<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="2. Logistic Regression">




  <meta name="keywords" content="机器学习, Rookie">










  <link rel="alternate" href="/default" title="Rookie">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.2">



<link rel="canonical" href="https://zhangydong.top/2019/01/06/Logistic-Regression/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.2">



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110425765-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110425765-2');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "3wSIBDvbuwPeOwNdvk5zjLHf-gzGzoHsz",
      appKey: "6GVMLrROY8HRyVW4odP5iKWI"
    });
  </script>





<script>
  window.config = {"leancloud":{"app_id":"3wSIBDvbuwPeOwNdvk5zjLHf-gzGzoHsz","app_key":"6GVMLrROY8HRyVW4odP5iKWI"},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> 2. Logistic Regression - Rookie </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Rookie</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Rookie</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          2. Logistic Regression
        
      </h1>

      <div class="post-meta">        
        
        <span class="post-time">
          2019-01-06
        </span>
        
          <span class="post-category">
            
              <a href="/categories/机器学习/">机器学习</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/01/06/Logistic-Regression/" data-title="2. Logistic Regression">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Classification"><span class="toc-text">Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-binary-classification"><span class="toc-text">1. binary classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-logistic-regression"><span class="toc-text">2. logistic regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Cost-Function"><span class="toc-text">2.1 Cost Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Gradient-Descent"><span class="toc-text">2.2 Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Pros-and-Cons1"><span class="toc-text">2.3 Pros and Cons1</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-multiclass-classification-one-vs-all"><span class="toc-text">2. multiclass classification: one-vs-all</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Example"><span class="toc-text">Example</span></a></li></ol></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <!-- TOC -->    
<a id="more"></a>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>

<img src="/2019/01/06/Logistic-Regression/2ndDay.PNG">
<p>If the values $y$ we now want to predict take only a small number of discrete values, we say it’s a classification problem.</p>
<h1 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h1><h2 id="1-binary-classification"><a href="#1-binary-classification" class="headerlink" title="1. binary classification"></a>1. binary classification</h2><p>For now, we will focus on the <strong>binary classification</strong> problem in which $y$ can take on only two values, 0 and 1.<br>(Most of what we say here will also generalize to the multiple-class case.)<br>For instance, if we are trying to build a spam classifier for email, then $x^{(i)}$ may be some features of a piece of email, and $y$ may be 1 if it is a piece of spam mail, and 0 otherwise. 0 is also called the <strong>negative class</strong>, and 1 the <strong>positive class</strong>, and they are sometimes also denoted by the symbols “$-$” and “$+$”. Given $x^{(i)}$, the corresponding $y^{(i)}$ is also called the <strong>label</strong> for the training example.</p>
<h2 id="2-logistic-regression"><a href="#2-logistic-regression" class="headerlink" title="2. logistic regression"></a>2. logistic regression</h2><p>We could approach the classification problem ignoring the fact that $y$ is discrete-valued, and use our old linear regression algorithm to try to predict $y$ given $x$. However, it is easy to construct examples where this method performs very poorly. Intuitively, it also doesn’t make sense for $h_θ(x)$ to take values larger than 1 or smaller than 0 when we know that $y ∈ {0, 1}$.<br>To fix this, lets change the form for our hypotheses $h_θ(x)$. We will choose<br>$$h _ { \theta } ( x ) = g \left( \theta ^ { T } x \right) = \frac { 1 } { 1 + e ^ { - \theta ^ { T } x } }$$<br>where $$g ( z ) = \frac { 1 } { 1 + e ^ { - z } }$$ is called the <strong>logistic function</strong> or the <strong>sigmoid function</strong>.<br>$h_\theta(x)$ will give us the <strong>probability</strong> that our output is <strong>1</strong>.<br><img src="/2019/01/06/Logistic-Regression/1.PNG"></p>
<h3 id="2-1-Cost-Function"><a href="#2-1-Cost-Function" class="headerlink" title="2.1 Cost Function"></a>2.1 Cost Function</h3><img src="/2019/01/06/Logistic-Regression/2.PNG">
<p>We can compress our cost function’s two conditional cases into one case:<br>$\operatorname { cost } \left( h _ { \theta } ( x ) , y \right) = - y \log ( h \theta ( x ) ) - ( 1 - y ) \log \left( 1 - h _ { \theta } ( x ) \right)$<br>We can fully write out our entire cost function as follows:<br>$J ( \theta ) = - \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \left[ y ^ { ( i ) } \log \left( h _ { \theta } \left( x ^ { ( i ) } \right) \right) + \left( 1 - y ^ { ( i ) } \right) \log \left( 1 - h _ { \theta } \left( x ^ { ( i ) } \right) \right) \right]$<br><img src="/2019/01/06/Logistic-Regression/3.PNG"></p>
<p>Note that writing the cost function in this way guarantees that $J(θ)$ is convex for logistic regression.</p>
<h3 id="2-2-Gradient-Descent"><a href="#2-2-Gradient-Descent" class="headerlink" title="2.2 Gradient Descent"></a>2.2 Gradient Descent</h3><img src="/2019/01/06/Logistic-Regression/4.PNG">
<p>or<br><img src="/2019/01/06/Logistic-Regression/5.PNG"></p>
<h3 id="2-3-Pros-and-Cons1"><a href="#2-3-Pros-and-Cons1" class="headerlink" title="2.3 Pros and Cons1"></a>2.3 Pros and Cons<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></h3><p>Advantages:</p>
<ul>
<li>Makes no assumptions about distributions of classes in feature space</li>
<li>Easily extended to multiple classes (multinomial regression)</li>
<li>Natural probabilistic view of class predictions Natural probabilistic view of class predictions</li>
<li>Quick to train</li>
<li>Very fast at classifying unknown records</li>
<li>Good accuracy for many simple data sets</li>
<li>Resistant to overfitting</li>
<li>Can interpret model coefficients as indicators of feature importance </li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Linear decision boundary<h2 id="2-multiclass-classification-one-vs-all"><a href="#2-multiclass-classification-one-vs-all" class="headerlink" title="2. multiclass classification: one-vs-all"></a>2. multiclass classification: one-vs-all</h2><img src="/2019/01/06/Logistic-Regression/6.PNG">
Train a logistic regression classifier $h_\theta(x)$ for each class￼ to predict the probability that ￼$￼y = i$￼.</li>
</ul>
<p>To make a prediction on a new $x$, pick the class ￼that maximizes $ h_\theta (x)$.</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p><a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html#sphx-glr-auto-examples-linear-model-plot-iris-logistic-py" target="_blank" rel="noopener">Logistic Regression 3-class Classifier</a> 鸢尾花数据集（iris dataset）supported by <a href="https://colab.research.google.com/" target="_blank" rel="noopener">Google Colab</a>.</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn import datasets

# import some data to play with
iris = datasets.load_iris()
X = iris.data[:, :2]  # we only take the first two features.
Y = iris.target

logreg = LogisticRegression(C=1e5, solver=&apos;lbfgs&apos;, multi_class=&apos;multinomial&apos;)

# Create an instance of Logistic Regression Classifier and fit the data.
logreg.fit(X, Y)

# Plot the decision boundary. For that, we will assign a color to each
# point in the mesh [x_min, x_max]x[y_min, y_max].
x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
h = .02  # step size in the mesh
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])

# Put the result into a color plot
Z = Z.reshape(xx.shape)
plt.figure(1, figsize=(4, 3))
plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)

# Plot also the training points
plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors=&apos;k&apos;, cmap=plt.cm.Paired)
plt.xlabel(&apos;Sepal length&apos;)
plt.ylabel(&apos;Sepal width&apos;)

plt.xlim(xx.min(), xx.max())
plt.ylim(yy.min(), yy.max())
plt.xticks(())
plt.yticks(())

plt.show()
</code></pre><img src="/2019/01/06/Logistic-Regression/logistic.PNG">
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="http://courses.washington.edu/css490/2012.Winter/lecture_slides/05b_logistic_regression.pdf" target="_blank" rel="noopener">css490</a> p20</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>
      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/机器学习/">机器学习</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/01/06/1月课程推荐/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">1月课程推荐</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2019/01/04/Linear-Regression/">
        <span class="next-text nav-default">1. Linear Regression</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDE0NS8xMDY4Mg==">
        <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
      </div>  
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:zhyd007@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
        
          <a href="https://github.com/Tom007Cheung" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tom-86-5/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2019

    <span class="fire">
      <i class="fa fa-fire" aria-hidden="true"></i>
    </span>
    <span class="author">TomCheung</span> 
    <div align="center"><a><img border="0" src="https://cc.amazingcounters.com/counter.php?i=3228910&c=9687043" alt="AmazingCounters.com"></a>
    访客(UV) since 2018/12/31
    </div>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  
   <script type="text/javascript">
	(function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
  </script>




    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.2"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  </body>
</html>
